\documentclass[a4paper,12pt]{article}
\usepackage{xspace}
\usepackage{relsize}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{pxfonts}
\newcommand\mT{\mathcal{T}}
\newcommand\T{$\mT$\xspace}
\newcommand\Tp{$\mT'$\xspace}
\newcommand\mtp{\models_{\mT'}}
\newcommand\syms{\mathop{\mathit{syms}}}
\newcommand\si{SMTInterpol\xspace}
\newcommand\sversion{2.0}
\newcommand\siv{\si~\sversion}
\newcommand\gen[1]{\mathop{gen}\nolimits_{#1}}
\newcommand\dom{\mathop{dom}}
\newcommand\todo[1]{\textcolor{red}{TODO: #1}}
\newcommand\seqcomp{\circledwedge}
\newcommand\choicecomp{\circledvee}

\title{Proposal: Program Variables in \siv}
\author{J{\"u}rgen Christ}
\date{2012/02/21}
\begin{document}
\maketitle
\section{General Remarks}
This proposal covers multiple sections that are intended for different audiences.
The next sections contain the basic proposal of program variables and their usage.
The final sections of this proposal introduce possible effects on the SMT solver.
These sections are rather low-level and mostly intended for the implementors of the solver and the interpolator.

\section{Introduction}
This document proposes the use of program variables and a special function to handle different generations.
The proposal tries to remove the use of term variables inside of SMT formulas which are let-bound according to the context.
A new constant is needed for every generation of the variable that occurs in the formula.
These constants impose an additional management overhead on the model checker and the solver.
Furthermore, the connection of the different formulas for sequential composition and non-deterministic choices are tedious and error-prone.
A more generalized methodology like the one proposed in this document can ease these topics.

\section{Program Variables and Generation}
We propose to define a \emph{program variable} for every variable occurring in the original program.
A program variable is an SMT term that can be used either directly as a term (in which case it stands for generation 0), or as the argument of the \emph{generation function} $\gen{M}: Term\rightarrow Term$ where $M$ is a map from program variables to positive integers.
Note that in this notation the program variable $x$ is the same than the term $\gen{\{x\mapsto0\}}x$.

\subsection{Properties of the Generation Function}
The generation function distributes over all operators except for the generation function itself, e.g.,
\begin{align*}
  \gen{M}(P\land Q)\equiv&(\gen{M}P)\land(\gen{M}Q)\\
  \gen{M}(f(t))\equiv&f(\gen{M}(t))
\end{align*}

The generation function applied to the generation function only composes the maps:
\[
\gen{M_1}(\gen{M_2}(t))\equiv\gen{M_1\circ M_2}(t)
\]
where the composition $M_1\circ M_2$ of two maps is defined as
\[
M_1\circ M_2=\left\{\begin{array}{l@{\quad\text{if}\quad}l}
M_1[x] + M_2[x] & x\in\dom(M_1)\cap\dom(M_2)\\
M_1[x] & x\in\dom(M_1)\setminus\dom(M_2)\\
M_2[x] & x\in\dom(M_2)\setminus\dom(M_1)\\
\end{array}\right.
\]
with the set of all keys of a map $M$ denoted by $\dom(M)$.

\subsection{Sample Transformation}\label{sec:sampletrans}
Consider the following program fragment:
\begin{verbatim}
while (x > 0)
  x = x - 1
\end{verbatim}

Using program variable $x$ we can encode one iteration through the loop as
\[
(x > 0) \land (\gen{\{x\mapsto 1\}}(x) = x + 1)
\]

\subsection{Implementation Notes}\label{sec:implementationnotes}
Terms containing program variables are stored in \emph{normalized form}.
A term is normalized if the lowest generation count of every program variable occurring in the term is 0.

Exploiting this normalization we can for every program variable occurring in a term store the biggest generation number.
This allows us to efficiently implement operations on terms containing program variables.

The crucial part in the implementation is the memory vs.\ time tradeoff to get the biggest generation number.
Two methods are possible here:
\begin{enumerate}
\item \emph{Lazy Computation}: Compute the biggest generation number for every program variable whenever it is needed.
The computation can be done in linear time over the size of the formula.
The method only needs additional memory when the generation numbers for program variables are computed, but does not need additional memory for every formula that contains program variables.
\item \emph{Memoization}: Remember for every formula the program variables and their highest generation number in a map.
A crucial point in this implementation is the sharing of the maps to reduce the memory footprint.
The basic idea is to only build a new map when building bigger formulas if there would be a change in the maps of the subformulas used to build the bigger formula.
Otherwise, the maps should be shared to reduce the memory usage.
An alternative might be to unify all maps since they should be constant.
This technique offers constant lookup of the maximal generation number, but needs additional space for every formula.
Since the space not only depends on the program variables contained in the formula but also on the generation number of this formula, the space consumption might outgrow the benefit of the constant lookup time.
\end{enumerate}

In the remainder of this proposal the function $\max_x(F)$ denotes the maximal generation number of program variable $x$ in formula $F$.

\subsection{Sequential Composition and Choices}
We now define the two basic operations on formulas containing program
variables: sequential composition and choices.
\todo{Do we need more?}

The \emph{sequential composition} $F_1\seqcomp F_2$ of two formulas $F_1$ and $F_2$ where the program variables contained in $F_1$ are denoted by the set $S$ is defined by
\[
F_1\seqcomp F_2\equiv F_1\land\gen{\{x\mapsto\max_x(F_1)\ |\ x\in S\}}(F_2)
\]
Intuitively, this formula denotes the conjunction of $F_1$ and $F_2$ where the generation number of every program variable occurring in $F_1$ gets increased in $F_2$ by the maximal number of $F_1$.
This definition reflects the connection of the outputs of $F_1$ to the inputs of $F_2$.

The \emph{(non-deterministic) choice} $F_1\choicecomp F_2$ of two formulas $F_1$ and $F_2$ where the program variables contained in $F_i$ are denoted by the set $S_i$ is defined by
\begin{align*}
F_1\choicecomp F_2\equiv&(F_1\land V_{s1}\land V_{o1}) \lor (F_2\land V_{s2}\land V_{o2})\\
V_{s1}\equiv&\bigwedge_{x\in \{y\ |\ y \in S_1\cap S_2 \land \max_y(F_1) < max_y(F_2)\}} \gen{\{x\mapsto\max_x(F_2)\}}(x) = \gen{\{x\mapsto\max_x(F_1)\}}(x)\\
V_{o1}\equiv&\bigwedge_{x\in S_2\setminus S_1}\gen{\{x\mapsto\max_x(F_2)\}}(x) = x\\
V_{s2}\equiv&\bigwedge_{x\in \{y\ |\ y \in S_2\cap S_1 \land \max_y(F_2) < max_y(F_1)\}} \gen{\{x\mapsto\max_x(F_1)\}}(x) = \gen{\{x\mapsto\max_x(F_2)\}}(x)\\
V_{o2}\equiv&\bigwedge_{x\in S_1\setminus S_2}\gen{\{x\mapsto\max_x(F_1)\}}(x) = x
\end{align*}
The intuition behind the different parts of the definition is as follows:
The formulas $V_s$ lift the program variables shared between the formulas $F_1$ and $F_2$ to the highest generation counter.
The formulas $V_o$ lift the program variables occurring only in one formula to the highest generation counter.
The definition of $F_1\choicecomp F_2$ then ensures that for every branch through the formula the maximal generation number of a variable is the same.

\subsection{Examples}
Consider the example from Subsection~\ref{sec:sampletrans}.
If we want to compose the constraint $F\equiv (x > 0) \land (\gen{\{x\mapsto 1\}}(x) = x + 1)$ with itself, i.e., build $F\seqcomp F$, we get 
\begin{align*}
F\seqcomp F\equiv&F\land\gen{x\mapsto 1}(F)\\
\equiv&F\land(\gen{\{x\mapsto 1\}}(x) > 0)\land \gen{\{x\mapsto 2\}}(x) = \gen{\{x\mapsto 1\}}(x) + 1
\end{align*}

If we have a formula $G\equiv (y > 0) \land (\gen{\{y\mapsto 1\}}(y) = x + 1)$ the choice $F\choicecomp G$ is
\begin{align*}
F\choicecomp G\equiv&(F\land\gen{\{y\mapsto 1\}}(y)=y)\lor(G\land\gen{\{x\mapsto 1\}}(x)=x)
\end{align*}

\section{Impacts on the SMT Solver and Interpolant Generator}
This section is merely a conceptual section for the implementors of the SMT solver and the interpolant generator.
It contains some first thoughts on possible impacts on these tools.
Additionally, this section hints at a possibility to implement program variable support for external SMT solvers.

\subsection{Generation-based Sharing and Deduction}
Whenever program variables contribute to a literal we can remember the lowest generation number of program variables, e.g., for the literal corresponding to $\gen{\{x\mapsto 1\}}(x) = x + 1$ we record 0 for the program variable $x$.
For a clause, we record the generations for which this clause exists.

For a resolvent clause, we can then easily compute a set of resolvent clauses with this information.
If a clause $C$ is derived by resolution of the clauses $C_i$ for $0\le i\le n$ and every $C_i$ has the set of generations $G_i$, then the resolvent clause exists for the generations $\bigcap_i G_i$.

\subsection{Generation-normalized Interpolants}
The definition of normalization from Subsection~\ref{sec:implementationnotes} suggest a normalized form for interpolants.
Using this notion of normalization, we should return interpolants whose lowest generation number for every variable is 0.
Then, implication checks between interpolant $I_1$ and $I_2$ can be done without modification of the formulas.
Inductivity checks need to apply the generation function to interpolant $I_2$ to adjust the generation of every individual variable.

\subsection{Implementing Program Variable Support for External Tools}
Since this program variable architecture is specific to \si, we should also provide a way to implement program variable support when communicating with external SMT solvers.
To do this, we can simply walk over the formula DAG and create for every program variable $x$ in generation $i$ a constant $x_i$ in the SMT solver.
This process should be triggered when a user asserts the formula which then corresponds to a series of declarations and finally an assert for the formula itself.
Note that we also need to support this when outputting formulas into SMTLIB format.
Hence, a generic solution would be to use SMTLIB annotations to deal with program variables.
The big problem then is the need to declare the constants for other solvers while \si would not need them.
We could work around this problem in \si by simply checking when \si is asked to declare a constant $x_0$ if a program variable $x$ already exists.
If this program variable already exists, we treat $x_0$ as the constant used to denote generation 0 of program variable $x$ and do not declare a new constant internally.

\end{document}
